{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linked Art - Create Summary Data Files - Activity\n",
    "\n",
    "This notebook will create summary data files for the MOMA alternative data transformed to Linked Art JSON-LD, for use with an exhibition browser.\n",
    "\n",
    "The JSON data files are in the `./data` directory as follows:\n",
    "\n",
    "- `./data`\n",
    "  - `activity`\n",
    "  - `group`\n",
    "  - `person`\n",
    "\n",
    "Where:\n",
    "- activity -> exhibition event \n",
    "- group -> organisation involved in exhibition events\n",
    "- person -> person involved in exhibition events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import json\n",
    "except:\n",
    "    %pip install json\n",
    "    import json\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Create JSON file for all *Activity* entities\n",
    "The following code will create a JSON file \n",
    "`events_all.json`\n",
    "\n",
    "The JSON file contains summary information about each group entity defined in the `data/person` directory:\n",
    "\n",
    "- id string\n",
    "- label string\n",
    "- _label string\n",
    "- start date\n",
    "- end date\n",
    "- location string\n",
    "- org string\n",
    "- venue string\n",
    "- identified_by []\n",
    "- timespan []\n",
    "- carried_out_by []\n",
    "- influenced_by []\n",
    "- other_exhibitions_same_time []\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define location of input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r output_activity_dir\n",
    "%store -r output_person_dir\n",
    "\n",
    "%store -r activity_all_file\n",
    "%store -r persons_all_file\n",
    "\n",
    "%store -r events_nonmoma\n",
    "%store -r json_suffix\n",
    "%store -r linked_data_filepath_group\n",
    "%store -r datavis_venue_exhibitions \n",
    "%store -r output_person_dir\n",
    "\n",
    "\n",
    "\n",
    "%store -r linked_data_dir\n",
    "%store -r linked_data_filepath_activity\n",
    "%store -r linked_data_filepath_person\n",
    "%store -r linked_data_filepath_group\n",
    "\n",
    "\n",
    "\n",
    "persons = \"persons\"\n",
    "json_suffix = \".json\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events_all.json \n",
    "\n",
    "Create summary file for all exhibitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "events = []\n",
    "\n",
    "template = {\n",
    "    \"id\": \"\",\n",
    "    \"label\": \"\",\n",
    "    \"start\": \"\",\n",
    "    \"end\": \"\",\n",
    "    \"location\": \"\",\n",
    "    \"org\": \"\",\n",
    "    \"venue\": \"\",\n",
    "    \"_label\": \"\",\n",
    "   \"coords\": \"\",\n",
    "    \"carried_out_by\":  [],\n",
    "    \"influenced_by\": [],\n",
    "    \"other_exhibitions_same_time\": [],\n",
    "   \n",
    "}\n",
    "\n",
    "for filename in os.listdir(linked_data_filepath_activity):\n",
    "    try:\n",
    "        with open(os.path.join(linked_data_filepath_activity, filename), 'r') as json_file:\n",
    "\n",
    "            data = json.load(json_file)\n",
    "            this = template.copy()\n",
    "\n",
    "            # id\n",
    "            this[\"id\"] = data.get(\"id\")\n",
    "            # label\n",
    "            # \"_label\": \"\",\n",
    "            this[\"_label\"] = data.get(\"_label\")\n",
    "            this[\"label\"] = data.get(\"_label\")\n",
    "\n",
    "            # \"start\": \"\",\n",
    "            this[\"start\"] = data.get(\"timespan\").get(\"begin_of_the_begin\")\n",
    "\n",
    "            # \"end\": \"\",\n",
    "            this[\"end\"] = data.get(\"timespan\").get(\"end_of_the_end\")\n",
    "            # \"location\": \"\",\n",
    "            this[\"location\"] = data.get(\"took_place_at\")[0].get(\"_label\")\n",
    "\n",
    "            # coords\n",
    "            this[\"coords\"] = data.get(\"took_place_at\")[0].get(\"defined_by\")\n",
    "            # \"org\": \"\",\n",
    "            this[\"org\"] = data.get(\"carried_out_by\")[0].get(\"_label\")\n",
    "   \n",
    "            # \"venue\": \"\",\n",
    "   \n",
    "  \n",
    "    \n",
    "   \n",
    "            # \"carried_out_by\":  [],\n",
    "            this[\"org\"] = data.get(\"carried_out_by\")[0].get(\"id\")\n",
    "   \n",
    "            list_influenced_by = []\n",
    "            # \"influenced_by\": []\n",
    "            for p in data.get(\"influenced_by\"):\n",
    "                list_influenced_by.append({\"id\": p.get(\"id\"), \"name\": p.get(\"_label\")})\n",
    "            this[\"influenced_by\"] = list_influenced_by\n",
    "\n",
    "            copy = this.copy()\n",
    "            events.append(copy)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "with open(os.path.join(output_activity_dir, activity_all_file), 'w') as file:\n",
    "    file.write(json.dumps({\"events\": events}, indent=2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add all exhibitions happening at same time, to events_all.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :param string: str, string to check for date\n",
    "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "#   https://stackoverflow.com/questions/9044084/efficient-date-range-overlap-calculation\n",
    "\n",
    "from datetime import datetime, date\n",
    "from collections import namedtuple\n",
    "Range = namedtuple('Range', ['start', 'end'])\n",
    "\n",
    "co_occurrence_list = []\n",
    "\n",
    "\n",
    "with open(os.path.join(output_activity_dir, activity_all_file), 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "\n",
    "    events = data.get(\"events\")\n",
    "    events2 = data.get(\"events\")\n",
    "\n",
    "    for event in events:\n",
    "       \n",
    "        start_date = event.get(\"start\")\n",
    "        end_date = event.get(\"end\")\n",
    "        event_id = event.get(\"id\")\n",
    "\n",
    "        if  start_date is None or end_date is None:\n",
    "                continue\n",
    "\n",
    "        start_date = start_date.split(\"T\")[0]\n",
    "        end_date = end_date.split(\"T\")[0]\n",
    "       \n",
    "\n",
    "        if start_date == \"\" or end_date == \"\":\n",
    "            continue\n",
    "\n",
    "        if (is_date(start_date, False) == False or is_date(end_date, False) == False):\n",
    "            continue\n",
    "\n",
    "        start_date = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "        end_date = datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "        r1 = Range(start=start_date, end=end_date)\n",
    "\n",
    "        other_events = []\n",
    "        event_list = []\n",
    "\n",
    "        for event2 in events2:\n",
    "\n",
    "            start_date2 = event2.get(\"start\")\n",
    "            end_date2 = event2.get(\"end\")\n",
    "            event_id2 = event2.get(\"id\")\n",
    "\n",
    "            if event_id == event_id2:\n",
    "                continue\n",
    "\n",
    "            if  start_date2 is None or end_date2 is None:\n",
    "                continue\n",
    "\n",
    "\n",
    "            start_date2 = start_date2.split(\"T\")[0]\n",
    "            end_date2 = end_date2.split(\"T\")[0]\n",
    "\n",
    "            if start_date2 == \"\" or end_date2 == \"\":\n",
    "                continue\n",
    "\n",
    "            if is_date(start_date2, False) == False or is_date(end_date2, False) == False:\n",
    "                continue\n",
    "\n",
    "        \n",
    "            start_date2 = datetime.strptime(start_date2, \"%Y-%m-%d\").date()\n",
    "            end_date2 = datetime.strptime(end_date2, \"%Y-%m-%d\").date()\n",
    "        \n",
    "            r2 = Range(start=start_date2, end=end_date2)\n",
    "\n",
    "            latest_start = max(r1.start, r2.start)\n",
    "            earliest_end = min(r1.end, r2.end)\n",
    "            delta = (earliest_end - latest_start).days + 1\n",
    "            overlap = max(0, delta) \n",
    "\n",
    "            if float(overlap) > 0:\n",
    "               \n",
    "                ex = dict({\"id\": event_id2, \"_label\": event2.get(\"_label\"), \"coords\": event2.get(\"coords\"), \"location\": event2.get(\"location\"), \"start\": event2.get(\"start\").split(\"T\")[0], \"end\": event2.get(\"end\").split(\"T\")[0], \"org\": event2.get(\"org\"), })\n",
    "                event_list.append(ex)\n",
    "           \n",
    "        \n",
    "        if len(event_list) > 0:\n",
    "            co_occurrence_list.append({event_id: event_list})\n",
    "\n",
    "    \n",
    "    with open(os.path.join(output_activity_dir, \"ex_co.json\"), 'w') as file:\n",
    "        file.write(json.dumps(co_occurrence_list, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events_all_startdate.json\n",
    "\n",
    "Create summary file of all exhibitions, sorted by start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "\n",
    "with open(os.path.join(output_activity_dir, activity_all_file), 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    events = data.get(\"events\")\n",
    "    sorted_events = sorted(events, key=itemgetter('start'))\n",
    "\n",
    "with open(os.path.join(output_activity_dir, \"events_all_startdate.json\"), 'w') as file:\n",
    "    file.write(json.dumps({\"events\": sorted_events}, indent=2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events_nonmoma.json and events_moma.json\n",
    "\n",
    "Create two files, containing exhibition summary data for non-MoMA organisations, and in separate file, MoMA organisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_nonmoma = []\n",
    "events_moma = []\n",
    "\n",
    "with open(os.path.join(output_activity_dir, activity_all_file), 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    events = data.get(\"events\")\n",
    "\n",
    "    for event in events:\n",
    "        if event.get(\"org\") in [\"https://www.moma.org/data/Group/inst3\", \"https://www.moma.org/data/Group/inst7\"]:\n",
    "            events_moma.append(event)\n",
    "        else:\n",
    "            events_nonmoma.append(event)\n",
    "            \n",
    "\n",
    "\n",
    "sorted_events_nonmoma = sorted(events_nonmoma, key=itemgetter('start'))\n",
    "with open(os.path.join(output_activity_dir, \"events_nonmoma.json\"), 'w') as file:\n",
    "    file.write(json.dumps({\"events\": sorted_events_nonmoma}, indent=2))\n",
    "\n",
    "sorted_events_moma = sorted(events_moma, key=itemgetter('start'))\n",
    "with open(os.path.join(output_activity_dir, \"events_moma.json\"), 'w') as file:\n",
    "    file.write(json.dumps({\"events\": sorted_events_moma}, indent=2))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events_all_startdate.json\n",
    "\n",
    "File containing all exhibitions ordered by start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "events = defaultdict(dict)\n",
    "\n",
    "counter = defaultdict(dict)\n",
    "\n",
    "template = {\n",
    "    \"id\": \"\",\n",
    "    \"_label\": \"\",\n",
    "    \"start\": \"\",\n",
    "    \"end\": \"\",\n",
    "    \"location\": \"\",\n",
    "    \"org\": \"\",\n",
    "    \"venue\": \"\",\n",
    "  \n",
    "    \"carried_out_by\":  [],\n",
    "    \"influenced_by\": [],\n",
    "   \n",
    "}\n",
    "\n",
    "for filename in os.listdir(linked_data_filepath_activity):\n",
    "    try:\n",
    "        with open(os.path.join(linked_data_filepath_activity, filename), 'r') as json_file:\n",
    "\n",
    "            data = json.load(json_file)\n",
    "            this = template.copy()\n",
    "\n",
    "            # id\n",
    "            this[\"id\"] = data.get(\"id\")\n",
    "            # label\n",
    "            # \"_label\": \"\",\n",
    "            this[\"_label\"] = data.get(\"_label\")\n",
    "            this[\"label\"] = data.get(\"_label\")\n",
    "\n",
    "            # \"start\": \"\",\n",
    "            this[\"start\"] = data.get(\"timespan\").get(\"begin_of_the_begin\").split(\"T\")[0]\n",
    "\n",
    "            \n",
    "\n",
    "            # \"end\": \"\",\n",
    "            this[\"end\"] = data.get(\"timespan\").get(\"end_of_the_end\").split(\"T\")[0]\n",
    "            # \"location\": \"\",\n",
    "            this[\"location\"] = data.get(\"took_place_at\")[0].get(\"_label\")\n",
    "            # \"org\": \"\",\n",
    "            this[\"org\"] = data.get(\"carried_out_by\")[0].get(\"_label\")\n",
    "   \n",
    "           \n",
    "            # \"carried_out_by\":  [],\n",
    "            this[\"carried_out_by\"] = data.get(\"carried_out_by\")[0].get(\"id\")\n",
    "   \n",
    "            list_influenced_by = []\n",
    "            \n",
    "            # \"influenced_by\": []\n",
    "            #for p in data.get(\"influenced_by\"):   \n",
    "            #    list_influenced_by.append({\"id\": p.get(\"id\"), \"name\": p.get(\"_label\")})\n",
    "           # this[\"influenced_by\"] = list_influenced_by\n",
    "\n",
    "            copy_of_event = this.copy()\n",
    "\n",
    "            start_year = this[\"start\"].split(\"-\")[0]\n",
    "            start_month = this[\"start\"].split(\"-\")[1]\n",
    "            \n",
    "            \n",
    "            if start_month not in events[start_year]:\n",
    "                events[start_year][start_month] = []\n",
    "           \n",
    "            events[start_year][start_month].append(copy_of_event)\n",
    "\n",
    "            if start_year not in counter:\n",
    "                counter[start_year] = 0\n",
    "            counter[start_year] += 1\n",
    "\n",
    "\n",
    "           # events.append(copy)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "#sorted_events = sorted(events, key=itemgetter('start'))\n",
    "with open(os.path.join(output_activity_dir, \"events_all_startdate.json\"), 'w') as file:\n",
    "    file.write(json.dumps({\"counter\": counter, \"events\": events}, indent=2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create events_nonmoma.json\n",
    "Create summary file of exhibitions organised by non-MoMA organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "events = []\n",
    "counter = defaultdict(dict)\n",
    "\n",
    "template = {\n",
    "    \"id\": \"\",\n",
    "    \"_label\": \"\",\n",
    "    \"start\": \"\",\n",
    "    \"end\": \"\",\n",
    "    \"location\": \"\",\n",
    "    \"org\": \"\",\n",
    "    \"venue\": \"\",\n",
    "  \n",
    "    \"carried_out_by\":  [],\n",
    "    \"influenced_by\": [],\n",
    "   \n",
    "}\n",
    "\n",
    "for filename in os.listdir(linked_data_filepath_activity):\n",
    "   \n",
    "        with open(os.path.join(linked_data_filepath_activity, filename), 'r') as json_file:\n",
    "\n",
    "            data = json.load(json_file)\n",
    "\n",
    "            org = this[\"carried_out_by\"] = data.get(\"carried_out_by\")[0].get(\"id\")\n",
    "            if org in [\"https://www.moma.org/data/Group/inst3\", \"https://www.moma.org/data/Group/inst7\"]:\n",
    "                continue\n",
    "\n",
    "\n",
    "            this = template.copy()\n",
    "\n",
    "            \n",
    "            this[\"id\"] = data.get(\"id\")\n",
    "            \n",
    "            this[\"_label\"] = data.get(\"_label\")\n",
    "            this[\"label\"] = data.get(\"_label\")\n",
    "\n",
    "            \n",
    "            this[\"start\"] = data.get(\"timespan\").get(\"begin_of_the_begin\").split(\"T\")[0]\n",
    "           \n",
    "            if \"end_of_the_end\" in data.get(\"timespan\"):\n",
    "                this[\"end\"] = data.get(\"timespan\").get(\"end_of_the_end\").split(\"T\")[0]\n",
    "           \n",
    "            if \"took_place_at\" in data:\n",
    "                this[\"location\"] =  data.get(\"took_place_at\")[0].get(\"_label\")\n",
    "            \n",
    "            this[\"org\"] = data.get(\"carried_out_by\")[0].get(\"_label\")\n",
    "            \n",
    "            this[\"carried_out_by\"] = data.get(\"carried_out_by\")[0].get(\"id\")\n",
    "   \n",
    "            list_influenced_by = []\n",
    "            \n",
    "            copy_of_event = this.copy()\n",
    "            \n",
    "            events.append(copy_of_event)\n",
    "\n",
    "   \n",
    "sorted_events = sorted(events, key=itemgetter('start'))\n",
    "with open(os.path.join(output_activity_dir, \"events_nonmoma.json\"), 'w') as file:\n",
    "    file.write(json.dumps(sorted_events, indent=2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events_moma_startdate.json\n",
    "\n",
    "File containing exhibitions organised by MoMA organisations ordered by start date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "events = defaultdict(dict)\n",
    "counter = defaultdict(dict)\n",
    "\n",
    "nonmoma_events = defaultdict(dict)\n",
    "nonmoma_counter = defaultdict(dict)\n",
    "\n",
    "template = {\n",
    "    \"id\": \"\",\n",
    "    \"_label\": \"\",\n",
    "    \"start\": \"\",\n",
    "    \"end\": \"\",\n",
    "    \"location\": \"\",\n",
    "    \"org\": \"\",\n",
    "    \"venue\": \"\",\n",
    "  \n",
    "    \"carried_out_by\":  [],\n",
    "    \"influenced_by\": [],\n",
    "   \n",
    "}\n",
    "\n",
    "for filename in os.listdir(linked_data_filepath_activity):\n",
    "    try:\n",
    "        with open(os.path.join(linked_data_filepath_activity, filename), 'r') as json_file:\n",
    "\n",
    "            data = json.load(json_file)\n",
    "\n",
    "            org = this[\"carried_out_by\"] = data.get(\"carried_out_by\")[0].get(\"id\")\n",
    "            if org not in [\"https://www.moma.org/data/Group/inst3\", \"https://www.moma.org/data/Group/inst7\"]:\n",
    "\n",
    "                this = template.copy()\n",
    "\n",
    "                # id\n",
    "                this[\"id\"] = data.get(\"id\")\n",
    "                # label\n",
    "                # \"_label\": \"\",\n",
    "                this[\"_label\"] = data.get(\"_label\")\n",
    "                this[\"label\"] = data.get(\"_label\")\n",
    "\n",
    "                # \"start\": \"\",\n",
    "                this[\"start\"] = data.get(\"timespan\").get(\"begin_of_the_begin\").split(\"T\")[0]\n",
    "\n",
    "            \n",
    "\n",
    "                # \"end\": \"\",\n",
    "                this[\"end\"] = data.get(\"timespan\").get(\"end_of_the_end\").split(\"T\")[0]\n",
    "                # \"location\": \"\",\n",
    "                this[\"location\"] = data.get(\"took_place_at\")[0].get(\"_label\")\n",
    "                # \"org\": \"\",\n",
    "                this[\"org\"] = data.get(\"carried_out_by\")[0].get(\"_label\")\n",
    "   \n",
    "           \n",
    "                # \"carried_out_by\":  [],\n",
    "                this[\"carried_out_by\"] = data.get(\"carried_out_by\")[0].get(\"id\")\n",
    "   \n",
    "                list_influenced_by = []\n",
    "            \n",
    "                copy_of_event = this.copy()\n",
    "\n",
    "                start_year = this[\"start\"].split(\"-\")[0]\n",
    "                start_month = this[\"start\"].split(\"-\")[1]\n",
    "            \n",
    "            \n",
    "                if start_month not in nonmoma_events[start_year]:\n",
    "                    nonmoma_events[start_year][start_month] = []\n",
    "           \n",
    "                nonmoma_events[start_year][start_month].append(copy_of_event)\n",
    "\n",
    "                if start_year not in nonmoma_counter:\n",
    "                    nonmoma_counter[start_year] = 0\n",
    "                    \n",
    "                nonmoma_counter[start_year] += 1\n",
    "\n",
    "                continue\n",
    "\n",
    "\n",
    "            this = template.copy()\n",
    "\n",
    "            # id\n",
    "            this[\"id\"] = data.get(\"id\")\n",
    "            # label\n",
    "            # \"_label\": \"\",\n",
    "            this[\"_label\"] = data.get(\"_label\")\n",
    "            this[\"label\"] = data.get(\"_label\")\n",
    "\n",
    "            # \"start\": \"\",\n",
    "            this[\"start\"] = data.get(\"timespan\").get(\"begin_of_the_begin\").split(\"T\")[0]\n",
    "\n",
    "            # \"end\": \"\",\n",
    "            this[\"end\"] = data.get(\"timespan\").get(\"end_of_the_end\").split(\"T\")[0]\n",
    "            # \"location\": \"\",\n",
    "            this[\"location\"] = data.get(\"took_place_at\")[0].get(\"_label\")\n",
    "            # \"org\": \"\",\n",
    "            this[\"org\"] = data.get(\"carried_out_by\")[0].get(\"_label\")\n",
    "   \n",
    "            # \"carried_out_by\":  [],\n",
    "            this[\"carried_out_by\"] = data.get(\"carried_out_by\")[0].get(\"id\")\n",
    "   \n",
    "            list_influenced_by = []\n",
    "            \n",
    "         \n",
    "            copy_of_event = this.copy()\n",
    "\n",
    "            start_year = this[\"start\"].split(\"-\")[0]\n",
    "            start_month = this[\"start\"].split(\"-\")[1]\n",
    "            \n",
    "            if start_month not in events[start_year]:\n",
    "                events[start_year][start_month] = []\n",
    "           \n",
    "            events[start_year][start_month].append(copy_of_event)\n",
    "\n",
    "            if start_year not in counter:\n",
    "                counter[start_year] = 0\n",
    "            counter[start_year] += 1\n",
    "\n",
    "\n",
    "         \n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "#sorted_events = sorted(events, key=itemgetter('start'))\n",
    "with open(os.path.join(output_activity_dir, \"events_moma_startdate.json\"), 'w') as file:\n",
    "    file.write(json.dumps({\"counter\": counter, \"events\": events}, indent=2))\n",
    "\n",
    "with open(os.path.join(output_activity_dir, \"events_nonmoma_startdate.json\"), 'w') as file:\n",
    "    file.write(json.dumps({\"counter\": nonmoma_counter, \"events\": nonmoma_events}, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# events ordered by organisation, year, month - moma and non-moma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "exhibitions = {\"counter\": [],\"events\": []}\n",
    "exhibitions_moma = {\"counter\": [],\"events\": []}\n",
    "exhibitions_nonmoma = {\"counter\": [],\"events\": []}\n",
    "\n",
    "counter = defaultdict(dict)\n",
    "\n",
    "\n",
    "number_by_org = {}\n",
    "\n",
    "exhibitions_by_org = {}\n",
    "\n",
    "data_file = \"events_all.json\"\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(output_activity_dir, data_file), 'r') as json_file:\n",
    "    \n",
    "    data = json.load(json_file)\n",
    "\n",
    "    events = data.get(\"events\")\n",
    "    sorted_events = sorted(events, key=itemgetter('start'))\n",
    "\n",
    "    for event in sorted_events:\n",
    "        org = event.get(\"org\")\n",
    "        start_date = event.get(\"start\")\n",
    "        start_date_year = start_date.split(\"-\")[0]\n",
    "        start_date_month = start_date.split(\"-\")[1]\n",
    "\n",
    "        filename = org.split(\"/\").pop() + json_suffix\n",
    "        \n",
    "        with open(os.path.join(linked_data_filepath_group, filename), 'r') as group_file:\n",
    "            groupdata = json.load(group_file)\n",
    "            label = groupdata.get(\"_label\")\n",
    "\n",
    "\n",
    "            if label in number_by_org:\n",
    "                number_by_org[label] += 1\n",
    "            else:\n",
    "                number_by_org[label] = 1\n",
    "\n",
    "            if label not in exhibitions_by_org:\n",
    "                exhibitions_by_org[label] = {}\n",
    "                exhibitions_by_org[label][start_date_year] = {}\n",
    "                exhibitions_by_org[label][start_date_year][start_date_month] = []\n",
    "\n",
    "            if label in exhibitions_by_org and start_date_year not in exhibitions_by_org[label]:\n",
    "                exhibitions_by_org[label][start_date_year] = {}\n",
    "                exhibitions_by_org[label][start_date_year][start_date_month] = []\n",
    "\n",
    "            if label in exhibitions_by_org and start_date_year in exhibitions_by_org[label] and start_date_month not in exhibitions_by_org[label][start_date_year]:\n",
    "                exhibitions_by_org[label][start_date_year][start_date_month] = []\n",
    "\n",
    "            exhibitions_by_org[label][start_date_year][start_date_month].append(event)\n",
    "\n",
    "            \n",
    "\n",
    "    # sort by name\n",
    "    number_by_org = dict(sorted(number_by_org.items(), key=lambda item: item[0]))\n",
    "\n",
    "\n",
    "exhibitions[\"counter\"] = number_by_org\n",
    "exhibitions[\"events\"] = exhibitions_by_org\n",
    "\n",
    "with open(os.path.join(output_activity_dir, \"events_all_org.json\"), 'w') as file:\n",
    "    file.write(json.dumps(exhibitions, indent=2))\n",
    "\n",
    "exhibitions_moma[\"counter\"].append(exhibitions[\"counter\"][\"The Museum of Modern Art\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
